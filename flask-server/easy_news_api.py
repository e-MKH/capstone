from flask import Flask, jsonify, request
import requests
from bs4 import BeautifulSoup
import time
import re

app = Flask(__name__)

@app.route('/easy-news', methods=['GET'])
def get_easy_news():
    start = time.time()
    print("ğŸ“¥ /easy-news ìš”ì²­ ìˆ˜ì‹ ë¨")

    base_url = "https://www.newsinlevels.com/level/level-1/"
    response = requests.get(base_url)
    print("ğŸŒ ë ˆë²¨1 í˜ì´ì§€ ìš”ì²­ ì™„ë£Œ")

    soup = BeautifulSoup(response.text, "html.parser")
    articles = []

    # 1. ë§í¬ë§Œ ìˆ˜ì§‘
    for a_tag in soup.select("h3 > a[href*='products']"):
        article_url = a_tag['href']
        print("ğŸ”— ê¸°ì‚¬ ë§í¬ ë°œê²¬:", article_url)

        # 2. Flask ì„œë²„ì— ë³¸ë¬¸ ì¶”ì¶œ ìš”ì²­
        try:
            extract_response = requests.post("http://localhost:5000/extract", json={"url": article_url})
            if extract_response.status_code == 200:
                result = extract_response.json()
                text = result.get("text", "")
                if len(text) > 0:
                    title = a_tag.get_text(strip=True)

                    # ê²Œì‹œì¼ ì¶”ì¶œ (ì˜ˆ: 05-05-2025 15:00)
                    date_match = re.search(r"\d{2}-\d{2}-\d{4} \d{2}:\d{2}", text)
                    published_at = date_match.group() if date_match else ""

                    articles.append({
                        "title": title,
                        "content": text,
                        "url": article_url,
                        "publishedAt": published_at
                    })
                    print("âœ… ë³¸ë¬¸ ì¶”ì¶œ ì„±ê³µ:", title)
            else:
                print("âš ï¸ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨ ìƒíƒœì½”ë“œ:", extract_response.status_code)
        except Exception as e:
            print("âŒ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", str(e))

        if len(articles) >= 5:
            break

    print(f"ğŸ“¦ ìµœì¢… ìˆ˜ì§‘ëœ ê¸°ì‚¬ ìˆ˜: {len(articles)}")
    print(f"â± ì²˜ë¦¬ ì‹œê°„: {time.time() - start:.2f}ì´ˆ")
    return jsonify(articles)


@app.route("/extract", methods=["POST"])
def extract_article():
    data = request.json
    url = data.get("url")

    try:
        print("â³ URL ë°›ìŒ:", url)
        page = requests.get(url)
        soup = BeautifulSoup(page.text, "html.parser")

        # ê¸°ì‚¬ ë³¸ë¬¸ ì¶”ì¶œ
        content_div = soup.find("div", class_="entry-content")
        text = content_div.get_text(separator="\n", strip=True) if content_div else ""

        print(f"âœ… ë³¸ë¬¸ ì¶”ì¶œ ì™„ë£Œ | ê¸¸ì´: {len(text)}")
        print("ğŸ“ ë³¸ë¬¸ ì•ë¶€ë¶„:", text[:200])
        return jsonify({"text": text})
    except Exception as e:
        print("âŒ ë³¸ë¬¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜:", str(e))
        return jsonify({"error": "ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨"}), 500


if __name__ == "__main__":
    print("âœ… ì„œë²„ ì‹œì‘ë¨: http://localhost:5001")
    app.run(debug=True, port=5001)